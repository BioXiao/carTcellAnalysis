---
title: "P89 RNA-seq CAR transcript analysis"
author: "James Eddy"
date: "March 30, 2016"
output: pdf_document 
---

```{r global_opts, echo=FALSE, cache=FALSE}
knitr::opts_chunk$set(fig.width=9, fig.align='center',
                      echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE)

## numbers >= 10^5 will be denoted in scientific notation,
## and rounded to 2 digits
options(scipen = 1, digits = 2)
```

```{r load_packages, cache=FALSE}
library(knitr)
library(stringr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(viridis)
library(rtracklayer)
library(ggthemes)
library(scales)
library(cowplot)

myCbPal <- colorblind_pal()(8)
myCbPal[c(1, 3, 6)] <- myCbPal[c(6, 1, 3)]
myCbPal[3] <- "#666666"
```

## Summary

I compared **coverage profiles** and **estimated abundances** for *CAR* and related transcripts using three sets of samples:

+ **P89 bulk:** sorted CD8+ T-cells, sequenced as bulk populations (expected to express *CAR*)
+ **P89 single-cell:** CD8+ T-cells, captured using **C1** instrument and sequenced invididually (expected to express *CAR*)
+ **P85 single-cell:** MAIT-cells, captured using **C1** and sequenced individually (not expected to express *CAR*)

Based on read coverage across the *CAR* transcript, the construct appears to be (i) expressed in bulk samples from P89; (ii) not expressed in single-cell samples from P85; (iii) expressed in a small fraction of single-cell samples from P89.

## Pipeline overview

The *CAR* detection pipeline utilizes two tools: [`Salmon`](https://github.com/COMBINE-lab/salmon) and [`RapMap`](https://github.com/COMBINE-lab/RapMap). Both use the concept of "lightweight" / "quasi-" / "pseudo" alignment to rapidly map RNA-seq reads to the transcriptome. `Salmon` is primarily geared towards transcript *quantification*, using a probabilistic algorithm to estimate abundance (i.e., counts or TPM) for each reference transcript. `RapMap` provides a stand-alone version of the quasi-mapper used under the hood by `Salmon`. The output of `RapMap` is a SAM-like record of aligned reads, which enables further inspection of transcript coverage. These tools were chosen because they're extremely fast &mdash; ~2-5 minutes to map/quantify an RNA-seq library with ~5-10 million reads &mdash; allowing for rapid prototyping and testing.

For each library, reads are mapped to a modified human reference transcriptome, including all annotated transcripts from the hg38 gene model GTF **plus** the *CAR* transcript sequence.

## Data used for analysis

Data presented below was generated and/or compiled from several sources:

+ **`sample_metrics_data`:**  sample annotation (e.g., donor ID, timepoint, etc.) as well sequencing & alignment metrics from RNA-seq processing 
+ **`sample_rapmap_data`:** read coverage measured across the length of the *CAR* transcript, based on mapping with the `RapMap` tool
+ **`sample_salmon_data`:** abundance estimates (e.g., TPM, count) produced by the `Salmon` tool for *CAR* and several relevant transcripts when mapping to a modified human reference transcriptome (hg38)
+ **`salmon_imgt_data`:** predicted/identified TCR junction sequences and alleles in single-cell libraries, as produced by assembly with `Trinity` followed by matching with `IMGT High V-QUEST`
+ **`gff_file`:** custom-built GTF file describing where individual segments are located along the length of the *CAR* transcript

```{r load_data}
load("data/sample_metrics_data.RData")
load("data/sample_rapmap_data.RData")
load("data/sample_salmon_data.RData")
load("data/sample_tcr_data.RData")

gff_file <- "data/annotation/carPlusRef.gtf"
xcripts_gtf <- import.gff2(gff_file)
xcript_dat <- as.data.frame(xcripts_gtf) %>% 
    filter(seqnames != "NR_047551") # removing because non-coding RNA

# quick fix for egfrt_dat
egfrt_dat <- egfrt_dat %>% 
    dplyr::rename(egfr_xcript = transcript_id) %>% 
    filter(seqnames != "NR_047551") # removing because non-coding RNA
```

```{r format_cov_dat}
# function to append CAR segment
get_segment <- Vectorize(function(pos) {
    xcript_dat %>% 
        filter(seqnames == "CAR-1",
               (start - 1) <= pos & (end + 1) >= pos) %>% 
        select(transcript_id) %>% 
        as.character()
})

lib_cov <- car_cov_dat %>% 
    filter(lib_id == car_cov_dat$lib_id[1]) %>% 
    mutate(segment = get_segment(pos)) %>% 
    select(pos, segment)

car_cov_dat <- car_cov_dat %>% 
    left_join(lib_cov, by = c("pos" = "pos")) %>% 
    filter(segment != "character(0)")
```

```{r data_clean_fxns}
# clean up duplicated headers
clean_dup_names <- function(df) {
    df_names <- names(df)
    is_dup_name <- duplicated(df_names)
    df_names[is_dup_name] <- str_c(df_names[is_dup_name], "2")
    names(df) <- df_names
    return(df)
}

# simplify library ID
simplify_lib_id <- function(df) {
    df_names <- names(df)
    is_lib_name <- str_detect(tolower(df_names), "lib.*id")
    df_names[is_lib_name] <- "lib_id"
    names(df) <- df_names
    
    df %>% 
        mutate(lib_id = str_extract(lib_id, "lib[0-9]+"))
}

# clean/relabel donor ID
clean_donor_ids <- function(df) {
    df %>% 
        mutate(donor_id = tolower(donor_id))
}

# relabel timepoints
relabel_timepoints <- function(df) {
    df %>% 
        mutate(timepoint = str_replace(timepoint, " ", ""),
               timepoint = str_replace(timepoint, "InfusionProduct", "IP"),
               timepoint = str_replace(timepoint, "Day0", "t0"),
               timepoint = str_replace(timepoint, "Day(7|8|9|12)", "t1"),
               timepoint = str_replace(timepoint, "Day(26|28|29|33)", "t2"))
}

# convert transcript names to segment names
relabel_transcripts <- function(df, xcript_dat) {
    df_names <- names(df)
    for (i in 1:length(df_names)) {
        if (df_names[i] %in% xcript_dat$seqnames) {
            xcript_row <- which(xcript_dat$seqnames %in% df_names[i])
            new_name <- xcript_dat$transcript_id[xcript_row]
            df_names[i] <- new_name
        }
    }
    names(df) <- df_names
    return(df)
}
```

```{r data_prep_fxn}
prep_cov_dat <- function(lib_dat, cov_dat, metric_dat) {
    lib_dat %>% 
        clean_dup_names() %>% 
        simplify_lib_id() %>%
        clean_donor_ids() %>% 
        select(lib_id, donor_id, timepoint) %>% 
        relabel_timepoints() %>% 
        left_join(cov_dat, by = c("lib_id" = "lib_id")) %>% 
        left_join(metric_dat %>% 
                      clean_dup_names() %>% 
                      simplify_lib_id() %>% 
                      select(lib_id, fastq_total_reads, 
                             median_cv_coverage, mapped_reads_w_dups),
                  by = c("lib_id" = "lib_id")) %>% 
        left_join(map_rate_dat, by = c("lib_id" = "lib_id")) %>% 
        mutate(mapped_reads = fastq_total_reads * map_rate,
               norm_cov = cov / mapped_reads) %>% 
        left_join(salmon_quant_dat %>% 
                      # filter(Name == "CAR-1") %>% 
                      select(lib_id, Name, TPM) %>% 
                      spread(Name, TPM) %>% 
                      dplyr::rename(CAR = `CAR-1`) %>% 
                      relabel_transcripts(xcript_dat)) %>% 
        left_join(jxn_summary_dat) %>% 
        mutate_each_(funs(. = ifelse(is.na(.), 0, .)), 
                     vars = c("tra_pos", "trb_pos", "tcr_pos"))
}
```

```{r plot_fxn}
plot_coverage <- function(formatted_cov_dat, gtf_dat, 
                          split = TRUE, fits_only = FALSE, 
                          color_by = "lib_num", fade_by = "log2(CAR + 1)",
                          hide_legend = FALSE) {
    
    # add lib numbers for coloring
    formatted_cov_dat <- formatted_cov_dat %>% 
        group_by(donor_id, timepoint) %>% 
        mutate(lib_num = dense_rank(lib_id) / n_distinct(lib_id),
               lib_num = as.character(lib_num)) %>% 
        ungroup()

    # determine plot height
    height <- log2(max(formatted_cov_dat$cov, na.rm = TRUE) + 1)
    
    # create color scale
    if (!fits_only) {
        gradient_stop <- myCbPal[3]
    } else {
        gradient_stop <- myCbPal[2]
    }
    num_libs <- n_distinct(formatted_cov_dat$lib_id)
    cc <- seq_gradient_pal(myCbPal[3], gradient_stop)(seq(0, 1, length.out = num_libs))
    
    # build plot
    p_cov <- ggplot() +
        geom_rect(data = gtf_dat, 
                  aes(xmin = start, xmax = end, ymin = 0, ymax = height, 
                      fill = segment),
                  alpha = 0.5, colour = "gray")
    if (!fits_only) {
        p_cov <- p_cov +
            geom_point(data = formatted_cov_dat, 
                       aes_string(x = "pos", y = "log2(cov + 1)", 
                                  alpha = fade_by, colour = color_by),
                       stroke = 0) +
            geom_smooth(data = formatted_cov_dat,
                        aes(x = pos, y = log2(cov + 1)),
                        se = FALSE, colour = myCbPal[2])
    } else {
        p_cov <- p_cov +
            geom_line(data = formatted_cov_dat,
                      aes_string(x = "pos", y = "log2(cov + 1)", 
                                 group = "lib_id", colour = color_by,
                                 alpha = fade_by),
                      stat = "smooth", method = "loess", 
                      se = FALSE, size = 1)
    }
    
    if (color_by == "lib_num") {
        p_cov <- p_cov + 
            scale_color_manual(values = cc) +
            guides(colour = FALSE)        
    } else {
        p_cov <- p_cov +
            scale_color_gradient(low = myCbPal[3], high = myCbPal[2])
    }
    
    if (is.numeric(fade_by)) {
        p_cov <- p_cov +
            scale_alpha_continuous(range = c(fade_by, fade_by)) +
            guides(alpha = FALSE)
    } else {
        p_cov <- p_cov +
            scale_alpha_continuous(range = c(0.2, 0.8))
    }
    
    if (color_by == fade_by) {
        p_cov <- p_cov +
            guides(alpha = FALSE)
    }

    p_cov <- p_cov +    
        scale_fill_viridis(discrete = TRUE) +
        theme_gray()
    
    if (split) {
        p_cov <- p_cov +
            facet_grid(donor_id ~ timepoint)
    }
    
    if (hide_legend) {
        p_cov <- p_cov +
            guides(fill = FALSE, colour = FALSE, alpha = FALSE)
    }
    return(p_cov)
}
```

## Results

### Visualizing *CAR* coverage & abundance

The plots below show read coverage from `RapMap` mapping across the length of the *CAR* sequence. Segments in the transcript, corresponding to the gene parts used to build the construct, are depicted by colored boxes in each plot. Transparency (i.e., alpha) is scaled based on the estimated abundance of the *CAR* transcript (TPM) as measured by `Salmon`.

#### Bulk libraries from project P89:

While expressed at what would be considered low levels, the *CAR* transcript appears to be present in all donors at all timepoints. Note that for all but the **x194~IP** timepoint (2 replicates), each plot shows data from a single library.

```{r prep_bulk_cov_dat}
bulk_cov_dat <- bulk_lib_dat %>% 
    prep_cov_dat(car_cov_dat, bulk_metric_dat) %>% 
    filter(donor_id %in% c("x145", "x194", "x228"))
```

```{r plot_bulk_cov, fig.height=4.5}
plot_coverage(bulk_cov_dat, car_dat)
```

#### Single-cell libraries from project P89:

In contrast, some single-cell libraries clearly show signs of *CAR* expression, but most do not. Each plot in this case shows data from all cells from a given donor/timepoint combination. The orange fit line depicts the average across all cells. 

```{r prep_p89_c1_cov_dat}
p89_c1_cov_dat <- sc_lib_dat %>% 
    prep_cov_dat(car_cov_dat, sc_metric_dat)
```

```{r plot_p89_c1_cov, fig.height=4.5}
plot_coverage(p89_c1_cov_dat, car_dat)
```

The table below shows the breakdown of libraries (cells) per group:
`r kable(p89_c1_cov_dat %>% group_by(donor_id, timepoint) %>% summarise(num_libs = n_distinct(lib_id)))`

#### Single-cell libraries from project P85:

As expected for the negative control, the MAIT cells from P85 show virtually no evidence of *CAR* expression.

```{r prep_p85_c1_cov_dat}
p85_c1_cov_dat <- p85_lib_dat %>% 
    prep_cov_dat(car_cov_dat, p85_metric_dat)
```

```{r plot_p85_c1_cov, fig.height=3}
plot_coverage(p85_c1_cov_dat, car_dat)
```

Here's the breakdown of libraries per group for P85:
`r kable(p89_c1_cov_dat %>% group_by(donor_id, timepoint) %>% summarise(num_libs = n_distinct(lib_id)))`

### Inspecting trends in *CAR* coverage among single-cell P89 libs

To simplify the plots (and make it easier to distinguish between libraries), below I've just shown the fit line of coverage for each library. Notably, these plots also show more clearly that, in many of the libraries with apparent *CAR* expression, the bulk of the signal appears to fall within the *EGFRt* region. I'll return to this point below.

```{r p89_cov_fits, fig.height=4.5}
p89_c1_cov_dat %>% 
    plot_coverage(car_dat, fits_only = TRUE)
```

<!-- leaving these plots out for now

#### *CAR* coverage vs. QC pass/fail

> **pass:** `median_cv_coverage` < 1 **AND** `mapped_reads_w_dups` > 0.7

```{r p89_cov_qc, fig.height=3}
p89_c1_cov_dat %>% 
    mutate(pass_qual = ifelse(median_cv_coverage < 1 &
                                  mapped_reads_w_dups > 0.7, 
                              "pass_qc", "fail_qc")) %>% 
    plot_coverage(car_dat, fits_only = TRUE, split = FALSE) +
    facet_wrap(~ pass_qual)
```

#### *CAR* coverage vs. presence of functional TCR junction

> **junction:** functional TRA **OR** TRB junction sequence detected

```{r p89_cov_jxn, fig.height=3}
p89_c1_cov_dat %>% 
    mutate(has_jxn = ifelse(tra_pos | trb_pos, 
                            "tra_or_trb", "no_jxn")) %>%
    plot_coverage(car_dat, fits_only = TRUE, split = FALSE) +
    facet_wrap(~ has_jxn)
```

#### *CAR* coverage vs. presence of TCR (paired junction)

> **TCR:** paired TRA **AND** TRB for the same library

```{r p89_cov_tcr, fig.height=3}
p89_c1_cov_dat %>% 
    mutate(has_tcr = ifelse(tcr_pos, 
                            "tra_and_trb", "no_tcr")) %>%
    plot_coverage(car_dat, fits_only = TRUE, split = FALSE) +
    facet_wrap(~ has_tcr)
```

-->

#### Correlation with abundance of non-*CAR* transcripts:

```{r format_xcript_table}
xcript_id_table <- xcript_dat %>% 
    filter(seqnames != "CAR-1") %>% 
    select(xcript_name = gene_id, segment_version = transcript_id)
```

The following human transcripts (which overlap the *CAR* sequence) were quantified by `Salmon`. The `xcript_name` (e.g., "CD28") corresponds to the "common" gene name for a particular *CAR* segment; `segment_version` includes a tag indicating record number, if multiple isoforms exist for the gene (e.g., "CD28tm\_r1") in the reference transcriptome.
`r kable(xcript_id_table)`

Each plot shows *CAR* coverage across libraries, but colored based on the estimated abundance of the respective transcript. In other words, a "brighter" fit line in the plot for *EGFRt_r4* indicates higher expression of that transcript in a library, even though the lines themselves still represent *CAR* transcript coverage.

```{r p89_all_segments_quant, fig.height=6, cache=TRUE}
gene_list <-c("CAR", 
      xcript_dat$transcript_id %>% 
          intersect(names(p89_c1_cov_dat))) %>% 
    as.list()
p_list <- lapply(gene_list, function(x) {
    p <- p89_c1_cov_dat %>% 
        plot_coverage(car_dat, fits_only = TRUE, split = FALSE, 
                      hide_legend = TRUE, 
                      color_by = sprintf("log2(%s + 1)", x),
                      fade_by = sprintf("log2(%s + 1)", x))
    return(p)
})
plot_grid(plotlist = p_list, ncol = 3, nrow = 4, 
          labels = unlist(gene_list), hjust = 0)
```

#### Estimated abundance of *EGFR* & *CAR* expression:

Once again, higher estimated expression of some *EGFR* transcripts (particularly *EGFRt_r2* and *EGFRt_r4*) appears to correspond to stronger evidence of *CAR* expression. I took a closer look at this by identifying the subsequence of each transcript that overlaps with the *EGFRt* segment of the *CAR* gene, then plotting the coverage from `RapMap` for each transcript. The region matching *EGFRt* is highlighted in the purple box (i.e., "transmembrane").

```{r prep_p89_c1_egfr_cov_dat}
p89_c1_egfr_cov_dat <- sc_lib_dat %>% 
    prep_cov_dat(egfr_cov_dat %>% 
                     filter(egfr_xcript != "EGFRt_r5"), # remove non-coding RNA
                 sc_metric_dat)
```

```{r p89_egfr_cov_fits, fig.height=4}
p89_c1_egfr_cov_dat %>% 
    filter(!is.na(egfr_xcript)) %>% 
    plot_coverage(egfrt_dat, fits_only = FALSE, split = FALSE) +
    facet_wrap(~ egfr_xcript, scales = "free_x")
```

It's pretty clear that the vast majority of reads mapping to any of the *EGFR* transcripts fall within the transmembrane region. There are other subsequences with some coverage outside of the transmembrane region, but these are fairly short and may overlap with other transcripts in hg38.

As for **why** reads from the *CAR* transcript are mostly mapping to the *EGFRt* segment, there are at least a couple possible explanations:

1. Because the *CAR* transcript is fairly long, degradation from both the 5' and 3' ends could lead to less coverage on either end of the transcript;
2. Libraries prepared using the Nextera XT kit (or more specifically, using the Clontech SMARTer cDNA synthesis kit for C1) show a fair amount of 3' bias, which could further (or primarily) contribute to the skew observed along the *CAR* transcript.

### Attempting to define *CAR* detection rules

I tried to come up with a relatively simple way to classify whether *CAR* was detected in a particular library.

<!-- leaving these plots out for now

#### Binarized *CAR* expression

> **expressed:** log2(TPM +1) > 0 for *CAR* transcript

```{r p89_cov_car, fig.height=6}
car_expr_dat_tpm <- p89_c1_cov_dat %>% 
    mutate(car_expr_tpm = ifelse(log2(CAR + 1) > 0, 
                                 "car_expr_tpm", "no_car_tpm")) %>%
    group_by(lib_id) %>% 
    mutate(nz_cov = max(cov) >= 2) %>% 
    ungroup()

car_expr_dat_tpm %>% 
    filter(!is.na(nz_cov)) %>% 
    plot_coverage(car_dat, fits_only = TRUE, split = FALSE) +
    facet_grid(car_expr_tpm ~ nz_cov)

tally_tpm <- car_expr_dat_tpm %>% 
    group_by(car_expr_tpm, nz_cov) %>% 
    summarise(n_libs = n_distinct(lib_id))
```

`r kable(tally_tpm)`

#### Quantification-based rule

> **expressed:** log2(TPM + 1) $\geq$ 2.5 in *CAR* or *EGFRt* transcripts **OR**
> log2(TPM + 1) > 2 in all *CAR* or *EGFRt* transcripts

```{r p89_cov_quant_rule, fig.height=6}
quant_indicator_dat <- salmon_quant_dat %>% 
    select(lib_id, Name, TPM) %>% 
    spread(Name, TPM) %>% 
    dplyr::rename(CAR = `CAR-1`) %>% 
    relabel_transcripts(xcript_dat) %>%
    mutate_each(funs(log2(. + 1)), -lib_id) %>% 
    rowwise() %>% 
    mutate(car_expr_quant = ifelse(
        max(CAR, EGFRt_r1, EGFRt_r2, EGFRt_r3, EGFRt_r4) >= 2.5 
        | min(CAR, EGFRt_r1, EGFRt_r2, EGFRt_r3, EGFRt_r4) > 1,
        "car_expr_quant", "no_car_quant"))

car_expr_dat_quant <- p89_c1_cov_dat %>% 
    left_join(quant_indicator_dat %>% 
                  select(lib_id, car_expr_quant)) %>% 
    group_by(lib_id) %>% 
    mutate(nz_cov = max(cov) >= 2) %>% 
    ungroup()

car_expr_dat_quant %>% 
    filter(!is.na(nz_cov)) %>% 
    plot_coverage(car_dat, fits_only = TRUE, split = FALSE) +
    facet_grid(car_expr_quant ~ nz_cov)

tally_quant <- car_expr_dat_quant %>% 
    group_by(car_expr_quant, nz_cov) %>% 
    summarise(n_libs = n_distinct(lib_id))
```

`r kable(tally_quant)`

-->

#### Coverage-based rule

> **expressed:** $\geq$ 10 positions with > 0 reads 
> in **ANY** of *CD19scFv*, *T2A*, or *EGFRt*

```{r p89_cov_cov_rule, fig.height=3}
cov_indicator_dat <- p89_c1_cov_dat %>% 
    group_by(lib_id, segment) %>% 
    filter(segment %in% c("CD19scFv", "T2A", "EGFRt")) %>% 
    summarise(hits = sum(cov > 0)) %>% 
    ungroup() %>% 
    group_by(lib_id) %>% 
    summarise(car_expr_cov = ifelse(any(hits >= 10),
                                    "car_expr_cov", "no_car_cov"))

car_expr_dat_cov <- p89_c1_cov_dat %>% 
    left_join(cov_indicator_dat %>% 
                  select(lib_id, car_expr_cov)) %>% 
    group_by(lib_id) %>% 
    mutate(nz_cov = max(cov) >= 2) %>% 
    ungroup()

car_expr_dat_cov %>% 
    filter(!is.na(nz_cov)) %>% 
    plot_coverage(car_dat, fits_only = TRUE, split = FALSE) +
    facet_grid(car_expr_cov ~ nz_cov)

tally_cov <- car_expr_dat_cov %>%  
    group_by(car_expr_cov, nz_cov) %>% 
    summarise(n_libs = n_distinct(lib_id))
```

`r kable(tally_cov)`

### Revisiting trends

Plotting the remaining 53 libraries with *CAR* detected based on **coverage**.

#### Timepoint vs. donor

```{r p89_cov_filtered, fig.height=4.5}
car_expr_dat_cov %>% 
    filter(!is.na(nz_cov),
           car_expr_cov == "car_expr_cov") %>% 
    plot_coverage(car_dat, fits_only = TRUE, split = TRUE)
```

#### Functional junction detection vs. *CAR* detection

```{r p89_cov_filtered_jxn, fig.height=3}
car_expr_dat_cov %>% 
    filter(!is.na(nz_cov)) %>% 
    mutate(has_jxn = ifelse(tra_pos | trb_pos, 
                            "tra_or_trb", "no_jxn")) %>%
    plot_coverage(car_dat, fits_only = TRUE, split = FALSE) +
    facet_grid(car_expr_cov ~ has_jxn)
```

<!-- leaving this plot out for now

#### Paired TCR junction detection vs. *CAR* detection

```{r p89_cov_filtered_tcr, fig.height=3}
car_expr_dat_cov %>% 
    filter(!is.na(nz_cov)) %>% 
    mutate(has_tcr = ifelse(tcr_pos, 
                            "tra_and_trb", "no_tcr")) %>%
    plot_coverage(car_dat, fits_only = TRUE, split = FALSE) +
    facet_grid(car_expr_cov ~ has_tcr)
```

-->

## Methods

### Data preprocessing

Prior to any computation with `Salmon` and `RapMap`, several steps were needed to prepare reference data and indexes:

#### Formatting/building reference transcriptome

To convert the *CAR* sequence information from lines in a Word document to something more usable (in this case, FASTA), I wrote a script to do most of the work for me. Writing the script took a bit of extra time, but it was useful for minimizing human error and replicated effort.

```
python scripts/format_fasta.py \
	data/sequence/carGeneRaw.txt \ # unformatted sequences, copied from Word doc into text file
	CAR \ # name of gene/transcript
	data/sequence/carTranscript.fasta \ # output FASTA file
	True \ # merge individual segments into a single FASTA record
	True # output is transcript (don't add artificial 'intron' buffer between segments)
```

To convert transcript records in the hg38 gene model GTF to the required FASTA format, I used the `gffread` function included with `cufflinks`.

```
gffread \
	-w data/sequence/hg38_transcripts.fa \ # output transcriptome FASTA
	-g genome.fa \ # reference genome (hg38) from iGenomes
	genes.gtf # reference gene models for hg38 from iGenomes
```

Finally, I simply pasted the *CAR* sequence to the top of the hg38 transcriptome FASTA.

```
cat data/sequence/carTranscript.fasta data/sequence/hg38_transcripts.fa > hg38_CAR_transcripts.fa
```

#### Formatting/building reference gene model GTF

For the purposes of visualization and some filtering tasks, I created a pseudo-GTF file with a record for each segment of the *CAR* transcript. Each segment (e.g., "CD28tm") is labeled as a unique 'transcript', and the chromosome is denoted as *CAR-1*. The start and end position of each segment is also included. I was able to use the `format_fasta.py` script for this, keeping the default option to not merge segments.

```
python scripts/format_fasta.py \
	data/sequence/carGeneRaw.txt \ # unformatted sequences, copied from Word document into text file
	CAR \ # name of gene/transcript
	data/sequence/carGeneParts.fasta \ # output FASTA file
```

Using a bit of digging and manual editing, I also added entries for each transcript in the reference human transcriptome that might overlap with *CAR* segments. In this case, the transcript ID (e.g., "NM\_001243077") is used as the chromosome name, the "common" gene name (e.g., "CD28") is used as the gene ID, and the corresponding *CAR* segment along with a tag indicating record number, if multiple isoforms exist for the gene (e.g., "CD28tm\_r1").

```
python scripts/gene_fasta_to_gtf.py \
	data/sequence/carGeneParts.fasta \
	CAR \
	data/annotation/carGeneParts.gtf
```

#### Building indexes

The commands for building indexes with `RapMap` and `Salmon`. Note: `docker` was used to run `RapMap`, as the tool is not currently available for Mac OS.

```
docker run --rm -v ${PWD}/data:/home/data jaeddy/rapmap:0.1.0-pre \ # loading docker image
	rapmap quasiindex \ # command to use rapmap executable & quasiindex module
    -t data/sequence/hg38_CAR_transcripts.fa \ # input reference transcriptome
    -i data/indexes/rapmap/hg38_CAR \ # index folder/prefix
    -k 19 #
```

```
tools/SalmonBeta-0.5.0_OSX-10.10/bin/salmon index # salmon executable & index module \
    -t data/sequence/hg38_CAR_transcripts.fa \
    -i data/indexes/salmon/hg38_CAR \
    --type quasi \
    -k 19
```

  

### Mapping & quantification

Both index building and actual mapping/quantification are included in the script `car_detect_pipe.sh`, which runs the pipeline an all library FASTQ files specified in a tab-delimited input list. The `bash` code is a bit messy, so I won't include it here, but the `RapMap` step proceeds as follows:

1. Map reads to reference transcriptome, save output SAM file
2. Convert SAM to BAM, sort, and index with `samtools`
3. Filter BAM records to only include reads mapping to *CAR* or relevant endogeneous transcripts (using `samtools`)
4. Index again with `samtools`)

For the `Salmon` step, outputs are saved as-is.

## Session info

```{r session_info}
sessionInfo()
```